# TODO module comments
# Functions for reading the input JSON files, and organizing them into data structures

# TODO currently not implemented: definiton files, param file, metadata file

import json
import os
import glob

def check_file_counts(directory):
    '''
    Returns true if the file counts are valid based on the DEVSMap specification.
    This means that there is at least one atomic model, at least one coupled model, 
    exactly 1 experiment file, and exactly 1 init_state file.

    Args:
        directory (str):    The directory where the json files are located.
    '''
    # One or more required
    has_atomic = False
    has_coupled = False
    # Specific number required
    experiment_filecount = 0
    init_states_filecount = 0

    for filename in os.listdir(directory):
        full_path = os.path.join(directory, filename)
        if os.path.isfile(full_path):

            if filename.endswith("_atomic.json"):
                has_atomic = True
            if filename.endswith("_coupled.json"):
                has_coupled = True
            if filename.endswith("_experiment.json"):
                experiment_filecount += 1
            if filename.endswith("_init_state.json"):
                init_states_filecount += 1

    valid_fileset = has_atomic and has_coupled and experiment_filecount == 1 and init_states_filecount == 1

    if not valid_fileset:
        #TODO handle this case after working on GUI
        print("Invalid fileset.")

    return valid_fileset


def clean_output_directory(main_directory, include_directory='include'):
    main_cpp_path = os.path.join(main_directory, 'main.cpp')
    
    # Delete main.cpp
    if os.path.isfile(main_cpp_path):
        os.remove(main_cpp_path)
        print(f"Deleted: {main_cpp_path}")
    else:
        print("main.cpp not found.")

    # Change this if there is ever a need for embedded systems with 
    # a different file structure
    include_path = os.path.join(main_directory, include_directory)

    # Delete all .hpp files in the subdirectory
    if os.path.isdir(include_path):
        hpp_files = glob.glob(os.path.join(include_path, '*.hpp'))
        for hpp_file in hpp_files:
            os.remove(hpp_file)
            print("Deleted: " + hpp_file)
    else:
        print("Subdirectory '" + include_directory +"' not found.")


def read_json_files(directory):
    '''
    Returns the raw data read in from the DEVSMap json files as a dictionary.

    Args:
        directory (str):    The directory where the json files are located.
    '''
    temp_data = {}
    for filename in os.listdir(directory):
        if filename.endswith(".json"):
            file_path = os.path.join(directory, filename)
            with open(file_path, 'r') as file:
                try: 
                    data = json.load(file)
                    temp_data[filename] = data
                except json.JSONDecodeError as e:
                    print(f"Error decoding JSON in file {filename}: {e}")
    return temp_data


def sort_json_files(json_data):
    '''
    Returns a dictionary of DEVSMap data sorted by the filename suffix 
    (the type of DEVSMap file).

    Args:
        json_data (dict):   The raw data read in from the DEVSMap json files. This data is 
                            obtained via the read_json_files(directory) function.
    '''
    data = {'atomic_models': [],    # 1 or more atomic models
            'coupled_models': [],   # 1 or more coupled models
            'experiment': None,     # exactly 1 experiment file
            'definition': [],       # 0 or more definition files
            'init_states': None,    # exactly 1 init_state file
            'param': None,          # 0 or 1 param files
            'metadata': None}       # 0 or 1 metadata files #TODO
    for key in json_data:
        words = key.split('_')
        file_type = words[len(words) - 1].split('.')[0]
        match file_type:
            case "atomic":
                data["atomic_models"].append(json_data[key])
            case "coupled":
                data["coupled_models"].append(json_data[key])
            case "experiment":
                data["experiment"] = json_data[key]
            #case "definition":
                #data["definition"].append(json_data[key])
            case "state":
                data["init_states"] = json_data[key]["init_states"]
            #case "param":
                #data["param"] = json_data[key]
            #case "metadata":
                #data["metadata"] = json_data[key]
            case _:
                print(f"Parsing for {file_type}.json files not yet implemented.\n")
    return data